*** IR Dump After Pre-ISel Intrinsic Lowering (pre-isel-intrinsic-lowering) ***
; ModuleID = 'o3.ll'
source_filename = "vectoradd_hip.cpp"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

@__const.__assert_fail.fmt = private unnamed_addr addrspace(4) constant [47 x i8] c"%s:%u: %s: Device-side assertion `%s' failed.\0A\00", align 16

; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}

; Function Attrs: nounwind speculatable willreturn memory(none)
declare align 4 ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.y() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.y() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.umin.i64(i64, i64) #2

; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: readwrite)
declare void @llvm.memcpy.p5.p4.i64(ptr addrspace(5) noalias nocapture writeonly, ptr addrspace(4) noalias nocapture readonly, i64, i1 immarg) #3

attributes #0 = { mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite) "amdgpu-flat-work-group-size"="1,1024" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx90a" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot3-insts,+dot4-insts,+dot5-insts,+dot6-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+gfx90a-insts,+mai-insts,+s-memrealtime,+s-memtime-inst" "uniform-work-group-size"="true" }
attributes #1 = { nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #2 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #3 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) "target-cpu"="gfx90a" }

!llvm.module.flags = !{!0, !1, !2}
!opencl.ocl.version = !{!3}
!llvm.ident = !{!4, !5}

!0 = !{i32 1, !"amdgpu_code_object_version", i32 400}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 8, !"PIC Level", i32 1}
!3 = !{i32 2, i32 0}
!4 = !{!"clang version 16.0.0 (git@github.com:whchung/llvm-project 26b4d8e720d0dd98f06e7c05ba232a49849d992d)"}
!5 = !{!"AMD clang version 14.0.0 (https://github.com/RadeonOpenCompute/llvm-project roc-5.2.0 22204 50d6d5d5b608d2abd6af44314abc6ad20036af3b)"}
!6 = !{i32 0, i32 1024}
!7 = !{!8, !8, i64 0}
!8 = !{!"float", !9, i64 0}
!9 = !{!"omnipotent char", !10, i64 0}
!10 = !{!"Simple C++ TBAA"}
!11 = !{}
*** IR Dump After Expand large div/rem (expand-large-div-rem) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After AMDGPU Printf lowering (amdgpu-printf-runtime-binding) ***
; ModuleID = 'o3.ll'
source_filename = "vectoradd_hip.cpp"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

@__const.__assert_fail.fmt = private unnamed_addr addrspace(4) constant [47 x i8] c"%s:%u: %s: Device-side assertion `%s' failed.\0A\00", align 16

; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}

; Function Attrs: nounwind speculatable willreturn memory(none)
declare align 4 ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.y() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.y() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.umin.i64(i64, i64) #2

; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: readwrite)
declare void @llvm.memcpy.p5.p4.i64(ptr addrspace(5) noalias nocapture writeonly, ptr addrspace(4) noalias nocapture readonly, i64, i1 immarg) #3

attributes #0 = { mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite) "amdgpu-flat-work-group-size"="1,1024" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx90a" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot3-insts,+dot4-insts,+dot5-insts,+dot6-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+gfx90a-insts,+mai-insts,+s-memrealtime,+s-memtime-inst" "uniform-work-group-size"="true" }
attributes #1 = { nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #2 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #3 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) "target-cpu"="gfx90a" }

!llvm.module.flags = !{!0, !1, !2}
!opencl.ocl.version = !{!3}
!llvm.ident = !{!4, !5}

!0 = !{i32 1, !"amdgpu_code_object_version", i32 400}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 8, !"PIC Level", i32 1}
!3 = !{i32 2, i32 0}
!4 = !{!"clang version 16.0.0 (git@github.com:whchung/llvm-project 26b4d8e720d0dd98f06e7c05ba232a49849d992d)"}
!5 = !{!"AMD clang version 14.0.0 (https://github.com/RadeonOpenCompute/llvm-project roc-5.2.0 22204 50d6d5d5b608d2abd6af44314abc6ad20036af3b)"}
!6 = !{i32 0, i32 1024}
!7 = !{!8, !8, i64 0}
!8 = !{!"float", !9, i64 0}
!9 = !{!"omnipotent char", !10, i64 0}
!10 = !{!"Simple C++ TBAA"}
!11 = !{}
*** IR Dump After Lower ctors and dtors for AMDGPU (amdgpu-lower-ctor-dtor) ***
; ModuleID = 'o3.ll'
source_filename = "vectoradd_hip.cpp"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

@__const.__assert_fail.fmt = private unnamed_addr addrspace(4) constant [47 x i8] c"%s:%u: %s: Device-side assertion `%s' failed.\0A\00", align 16

; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}

; Function Attrs: nounwind speculatable willreturn memory(none)
declare align 4 ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.y() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.y() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.umin.i64(i64, i64) #2

; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: readwrite)
declare void @llvm.memcpy.p5.p4.i64(ptr addrspace(5) noalias nocapture writeonly, ptr addrspace(4) noalias nocapture readonly, i64, i1 immarg) #3

attributes #0 = { mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite) "amdgpu-flat-work-group-size"="1,1024" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx90a" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot3-insts,+dot4-insts,+dot5-insts,+dot6-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+gfx90a-insts,+mai-insts,+s-memrealtime,+s-memtime-inst" "uniform-work-group-size"="true" }
attributes #1 = { nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #2 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #3 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) "target-cpu"="gfx90a" }

!llvm.module.flags = !{!0, !1, !2}
!opencl.ocl.version = !{!3}
!llvm.ident = !{!4, !5}

!0 = !{i32 1, !"amdgpu_code_object_version", i32 400}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 8, !"PIC Level", i32 1}
!3 = !{i32 2, i32 0}
!4 = !{!"clang version 16.0.0 (git@github.com:whchung/llvm-project 26b4d8e720d0dd98f06e7c05ba232a49849d992d)"}
!5 = !{!"AMD clang version 14.0.0 (https://github.com/RadeonOpenCompute/llvm-project roc-5.2.0 22204 50d6d5d5b608d2abd6af44314abc6ad20036af3b)"}
!6 = !{i32 0, i32 1024}
!7 = !{!8, !8, i64 0}
!8 = !{!"float", !9, i64 0}
!9 = !{!"omnipotent char", !10, i64 0}
!10 = !{!"Simple C++ TBAA"}
!11 = !{}
*** IR Dump After Early propagate attributes from kernels to functions (amdgpu-propagate-attributes-early) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After AMDGPU Lower Intrinsics (amdgpu-lower-intrinsics) ***
; ModuleID = 'o3.ll'
source_filename = "vectoradd_hip.cpp"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

@__const.__assert_fail.fmt = private unnamed_addr addrspace(4) constant [47 x i8] c"%s:%u: %s: Device-side assertion `%s' failed.\0A\00", align 16

; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}

; Function Attrs: nounwind speculatable willreturn memory(none)
declare align 4 ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.y() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.y() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.umin.i64(i64, i64) #2

; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: readwrite)
declare void @llvm.memcpy.p5.p4.i64(ptr addrspace(5) noalias nocapture writeonly, ptr addrspace(4) noalias nocapture readonly, i64, i1 immarg) #3

attributes #0 = { mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite) "amdgpu-flat-work-group-size"="1,1024" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx90a" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot3-insts,+dot4-insts,+dot5-insts,+dot6-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+gfx90a-insts,+mai-insts,+s-memrealtime,+s-memtime-inst" "uniform-work-group-size"="true" }
attributes #1 = { nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #2 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #3 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) "target-cpu"="gfx90a" }

!llvm.module.flags = !{!0, !1, !2}
!opencl.ocl.version = !{!3}
!llvm.ident = !{!4, !5}

!0 = !{i32 1, !"amdgpu_code_object_version", i32 400}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 8, !"PIC Level", i32 1}
!3 = !{i32 2, i32 0}
!4 = !{!"clang version 16.0.0 (git@github.com:whchung/llvm-project 26b4d8e720d0dd98f06e7c05ba232a49849d992d)"}
!5 = !{!"AMD clang version 14.0.0 (https://github.com/RadeonOpenCompute/llvm-project roc-5.2.0 22204 50d6d5d5b608d2abd6af44314abc6ad20036af3b)"}
!6 = !{i32 0, i32 1024}
!7 = !{!8, !8, i64 0}
!8 = !{!"float", !9, i64 0}
!9 = !{!"omnipotent char", !10, i64 0}
!10 = !{!"Simple C++ TBAA"}
!11 = !{}
*** IR Dump After AMDGPU Inline All Functions (amdgpu-always-inline) ***
; ModuleID = 'o3.ll'
source_filename = "vectoradd_hip.cpp"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

@__const.__assert_fail.fmt = private unnamed_addr addrspace(4) constant [47 x i8] c"%s:%u: %s: Device-side assertion `%s' failed.\0A\00", align 16

; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}

; Function Attrs: nounwind speculatable willreturn memory(none)
declare align 4 ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.y() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.y() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.umin.i64(i64, i64) #2

; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: readwrite)
declare void @llvm.memcpy.p5.p4.i64(ptr addrspace(5) noalias nocapture writeonly, ptr addrspace(4) noalias nocapture readonly, i64, i1 immarg) #3

attributes #0 = { mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite) "amdgpu-flat-work-group-size"="1,1024" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx90a" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot3-insts,+dot4-insts,+dot5-insts,+dot6-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+gfx90a-insts,+mai-insts,+s-memrealtime,+s-memtime-inst" "uniform-work-group-size"="true" }
attributes #1 = { nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #2 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #3 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) "target-cpu"="gfx90a" }

!llvm.module.flags = !{!0, !1, !2}
!opencl.ocl.version = !{!3}
!llvm.ident = !{!4, !5}

!0 = !{i32 1, !"amdgpu_code_object_version", i32 400}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 8, !"PIC Level", i32 1}
!3 = !{i32 2, i32 0}
!4 = !{!"clang version 16.0.0 (git@github.com:whchung/llvm-project 26b4d8e720d0dd98f06e7c05ba232a49849d992d)"}
!5 = !{!"AMD clang version 14.0.0 (https://github.com/RadeonOpenCompute/llvm-project roc-5.2.0 22204 50d6d5d5b608d2abd6af44314abc6ad20036af3b)"}
!6 = !{i32 0, i32 1024}
!7 = !{!8, !8, i64 0}
!8 = !{!"float", !9, i64 0}
!9 = !{!"omnipotent char", !10, i64 0}
!10 = !{!"Simple C++ TBAA"}
!11 = !{}
*** IR Dump After Inliner for always_inline functions (always-inline) ***; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Inliner for always_inline functions (always-inline) ***
Printing <null> Function
*** IR Dump After A No-Op Barrier Pass (barrier) ***
; ModuleID = 'o3.ll'
source_filename = "vectoradd_hip.cpp"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

@__const.__assert_fail.fmt = private unnamed_addr addrspace(4) constant [47 x i8] c"%s:%u: %s: Device-side assertion `%s' failed.\0A\00", align 16

; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}

; Function Attrs: nounwind speculatable willreturn memory(none)
declare align 4 ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.y() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.y() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.umin.i64(i64, i64) #2

; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: readwrite)
declare void @llvm.memcpy.p5.p4.i64(ptr addrspace(5) noalias nocapture writeonly, ptr addrspace(4) noalias nocapture readonly, i64, i1 immarg) #3

attributes #0 = { mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite) "amdgpu-flat-work-group-size"="1,1024" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx90a" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot3-insts,+dot4-insts,+dot5-insts,+dot6-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+gfx90a-insts,+mai-insts,+s-memrealtime,+s-memtime-inst" "uniform-work-group-size"="true" }
attributes #1 = { nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #2 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #3 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) "target-cpu"="gfx90a" }

!llvm.module.flags = !{!0, !1, !2}
!opencl.ocl.version = !{!3}
!llvm.ident = !{!4, !5}

!0 = !{i32 1, !"amdgpu_code_object_version", i32 400}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 8, !"PIC Level", i32 1}
!3 = !{i32 2, i32 0}
!4 = !{!"clang version 16.0.0 (git@github.com:whchung/llvm-project 26b4d8e720d0dd98f06e7c05ba232a49849d992d)"}
!5 = !{!"AMD clang version 14.0.0 (https://github.com/RadeonOpenCompute/llvm-project roc-5.2.0 22204 50d6d5d5b608d2abd6af44314abc6ad20036af3b)"}
!6 = !{i32 0, i32 1024}
!7 = !{!8, !8, i64 0}
!8 = !{!"float", !9, i64 0}
!9 = !{!"omnipotent char", !10, i64 0}
!10 = !{!"Simple C++ TBAA"}
!11 = !{}
*** IR Dump After Lower OpenCL enqueued blocks (amdgpu-lower-enqueued-block) ***
; ModuleID = 'o3.ll'
source_filename = "vectoradd_hip.cpp"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

@__const.__assert_fail.fmt = private unnamed_addr addrspace(4) constant [47 x i8] c"%s:%u: %s: Device-side assertion `%s' failed.\0A\00", align 16

; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}

; Function Attrs: nounwind speculatable willreturn memory(none)
declare align 4 ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.y() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.y() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.umin.i64(i64, i64) #2

; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: readwrite)
declare void @llvm.memcpy.p5.p4.i64(ptr addrspace(5) noalias nocapture writeonly, ptr addrspace(4) noalias nocapture readonly, i64, i1 immarg) #3

attributes #0 = { mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite) "amdgpu-flat-work-group-size"="1,1024" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx90a" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot3-insts,+dot4-insts,+dot5-insts,+dot6-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+gfx90a-insts,+mai-insts,+s-memrealtime,+s-memtime-inst" "uniform-work-group-size"="true" }
attributes #1 = { nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #2 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #3 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) "target-cpu"="gfx90a" }

!llvm.module.flags = !{!0, !1, !2}
!opencl.ocl.version = !{!3}
!llvm.ident = !{!4, !5}

!0 = !{i32 1, !"amdgpu_code_object_version", i32 400}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 8, !"PIC Level", i32 1}
!3 = !{i32 2, i32 0}
!4 = !{!"clang version 16.0.0 (git@github.com:whchung/llvm-project 26b4d8e720d0dd98f06e7c05ba232a49849d992d)"}
!5 = !{!"AMD clang version 14.0.0 (https://github.com/RadeonOpenCompute/llvm-project roc-5.2.0 22204 50d6d5d5b608d2abd6af44314abc6ad20036af3b)"}
!6 = !{i32 0, i32 1024}
!7 = !{!8, !8, i64 0}
!8 = !{!"float", !9, i64 0}
!9 = !{!"omnipotent char", !10, i64 0}
!10 = !{!"Simple C++ TBAA"}
!11 = !{}
*** IR Dump After Lower uses of LDS variables from non-kernel functions (amdgpu-lower-module-lds) ***
; ModuleID = 'o3.ll'
source_filename = "vectoradd_hip.cpp"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

@__const.__assert_fail.fmt = private unnamed_addr addrspace(4) constant [47 x i8] c"%s:%u: %s: Device-side assertion `%s' failed.\0A\00", align 16

; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}

; Function Attrs: nounwind speculatable willreturn memory(none)
declare align 4 ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.y() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.y() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.umin.i64(i64, i64) #2

; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: readwrite)
declare void @llvm.memcpy.p5.p4.i64(ptr addrspace(5) noalias nocapture writeonly, ptr addrspace(4) noalias nocapture readonly, i64, i1 immarg) #3

attributes #0 = { mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite) "amdgpu-flat-work-group-size"="1,1024" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx90a" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot3-insts,+dot4-insts,+dot5-insts,+dot6-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+gfx90a-insts,+mai-insts,+s-memrealtime,+s-memtime-inst" "uniform-work-group-size"="true" }
attributes #1 = { nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #2 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #3 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) "target-cpu"="gfx90a" }

!llvm.module.flags = !{!0, !1, !2}
!opencl.ocl.version = !{!3}
!llvm.ident = !{!4, !5}

!0 = !{i32 1, !"amdgpu_code_object_version", i32 400}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 8, !"PIC Level", i32 1}
!3 = !{i32 2, i32 0}
!4 = !{!"clang version 16.0.0 (git@github.com:whchung/llvm-project 26b4d8e720d0dd98f06e7c05ba232a49849d992d)"}
!5 = !{!"AMD clang version 14.0.0 (https://github.com/RadeonOpenCompute/llvm-project roc-5.2.0 22204 50d6d5d5b608d2abd6af44314abc6ad20036af3b)"}
!6 = !{i32 0, i32 1024}
!7 = !{!8, !8, i64 0}
!8 = !{!"float", !9, i64 0}
!9 = !{!"omnipotent char", !10, i64 0}
!10 = !{!"Simple C++ TBAA"}
!11 = !{}
*** IR Dump After Infer address spaces (infer-address-spaces) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Expand Atomic instructions (atomic-expand) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After AMDGPU Promote Alloca (amdgpu-promote-alloca) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After SROA (sroa) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Canonicalize natural loops (loop-simplify) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After LCSSA Verifier (lcssa-verification) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Loop-Closed SSA Form Pass (lcssa) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Split GEPs to a variadic base and a constant offset for better CSE (separate-const-offset-from-gep) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Straight line strength reduction (slsr) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Early CSE (early-cse) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Nary reassociation (nary-reassociate) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Early CSE (early-cse) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After AMDGPU IR optimizations (amdgpu-codegenprepare) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Module Verifier (verify) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Canonicalize natural loops (loop-simplify) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Merge contiguous icmps into a memcmp (mergeicmps) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Expand memcmp() to load/stores (expandmemcmp) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Lower constant intrinsics (lower-constant-intrinsics) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Remove unreachable blocks from the CFG (unreachableblockelim) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Constant Hoisting (consthoist) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Replace intrinsics with calls to vector library (replace-with-veclib) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Partially inline calls to library functions (partially-inline-libcalls) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Expand vector predication intrinsics (expandvp) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Scalarize Masked Memory Intrinsics (scalarize-masked-mem-intrin) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Expand reduction intrinsics (expand-reductions) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After TLS Variable Hoist (tlshoist) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Early CSE (early-cse) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After AMDGPU Attributor (amdgpu-attributor) ***
; ModuleID = 'o3.ll'
source_filename = "vectoradd_hip.cpp"
target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7"
target triple = "amdgcn-amd-amdhsa"

@__const.__assert_fail.fmt = private unnamed_addr addrspace(4) constant [47 x i8] c"%s:%u: %s: Device-side assertion `%s' failed.\0A\00", align 16

; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}

; Function Attrs: nounwind speculatable willreturn memory(none)
declare align 4 ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.y() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.x() #1

; Function Attrs: nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workgroup.id.y() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.umin.i64(i64, i64) #2

; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: readwrite)
declare void @llvm.memcpy.p5.p4.i64(ptr addrspace(5) noalias nocapture writeonly, ptr addrspace(4) noalias nocapture readonly, i64, i1 immarg) #3

attributes #0 = { mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite) "amdgpu-flat-work-group-size"="1,1024" "amdgpu-no-dispatch-id" "amdgpu-no-dispatch-ptr" "amdgpu-no-heap-ptr" "amdgpu-no-hostcall-ptr" "amdgpu-no-implicitarg-ptr" "amdgpu-no-lds-kernel-id" "amdgpu-no-multigrid-sync-arg" "amdgpu-no-queue-ptr" "amdgpu-no-workgroup-id-x" "amdgpu-no-workgroup-id-z" "amdgpu-no-workitem-id-x" "amdgpu-no-workitem-id-z" "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx90a" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot2-insts,+dot3-insts,+dot4-insts,+dot5-insts,+dot6-insts,+dot7-insts,+dpp,+flat-address-space,+gfx8-insts,+gfx9-insts,+gfx90a-insts,+mai-insts,+s-memrealtime,+s-memtime-inst" "uniform-work-group-size"="true" }
attributes #1 = { nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #2 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) "target-cpu"="gfx90a" }
attributes #3 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) "target-cpu"="gfx90a" }

!llvm.module.flags = !{!0, !1, !2}
!opencl.ocl.version = !{!3}
!llvm.ident = !{!4, !5}

!0 = !{i32 1, !"amdgpu_code_object_version", i32 400}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 8, !"PIC Level", i32 1}
!3 = !{i32 2, i32 0}
!4 = !{!"clang version 16.0.0 (git@github.com:whchung/llvm-project 26b4d8e720d0dd98f06e7c05ba232a49849d992d)"}
!5 = !{!"AMD clang version 14.0.0 (https://github.com/RadeonOpenCompute/llvm-project roc-5.2.0 22204 50d6d5d5b608d2abd6af44314abc6ad20036af3b)"}
!6 = !{i32 0, i32 1024}
!7 = !{!8, !8, i64 0}
!8 = !{!"float", !9, i64 0}
!9 = !{!"omnipotent char", !10, i64 0}
!10 = !{!"Simple C++ TBAA"}
!11 = !{}
*** IR Dump After AMDGPU Annotate Kernel Features (amdgpu-annotate-kernel-features) ***; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After AMDGPU Lower Kernel Arguments (amdgpu-lower-kernel-arguments) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After CodeGen Prepare (codegenprepare) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After GPU Load and Store Vectorizer (load-store-vectorizer) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Lower SwitchInst's to branches (lowerswitch) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Lower invoke and unwind, for unwindless code generators (lowerinvoke) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Remove unreachable blocks from the CFG (unreachableblockelim) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Flatten the CFG (flattencfg) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After AMDGPU IR late optimizations (amdgpu-late-codegenprepare) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Code sinking (sink) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Unify divergent function exit nodes (amdgpu-unify-divergent-exit-nodes) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Lower SwitchInst's to branches (lowerswitch) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Convert irreducible control-flow into natural loops (fix-irreducible) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Fixup each natural loop to have a single exit block (unify-loop-exits) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Structurize control flow (structurizecfg) ***
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
*** IR Dump After AMDGPU Annotate Uniform Values (amdgpu-annotate-uniform) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After SI annotate control flow (si-annotate-control-flow) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After AMDGPU Rewrite Undef for PHI (amdgpu-rewrite-undef-for-phi) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After LCSSA Verifier (lcssa-verification) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Loop-Closed SSA Form Pass (lcssa) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After DummyCGSCCPass (DummyCGSCCPass) ***; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Safe Stack instrumentation pass (safe-stack) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
*** IR Dump After Module Verifier (verify) ***
; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite)
define protected amdgpu_kernel void @_Z15vectoradd_floatPKfS0_Pf(ptr addrspace(1) noalias nocapture noundef readonly %a.coerce, ptr addrspace(1) noalias nocapture noundef readonly %b.coerce, ptr addrspace(1) noalias nocapture noundef writeonly %c.coerce) local_unnamed_addr #0 {
entry:
  %_Z15vectoradd_floatPKfS0_Pf.kernarg.segment = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %0 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %mul = shl i32 %0, 8
  %1 = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !6
  %add = add i32 %mul, %1
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.y()
  %3 = tail call i32 @llvm.amdgcn.workitem.id.y(), !range !6
  %add8 = add i32 %2, %3
  %mul10 = shl nsw i32 %add8, 10
  %add11 = add nsw i32 %add, %mul10
  %idxprom = sext i32 %add11 to i64
  %arrayidx = getelementptr inbounds float, ptr addrspace(1) %a.coerce, i64 %idxprom
  %4 = load float, ptr addrspace(1) %arrayidx, align 4, !tbaa !7, !amdgpu.noclobber !11
  %arrayidx13 = getelementptr inbounds float, ptr addrspace(1) %b.coerce, i64 %idxprom
  %5 = load float, ptr addrspace(1) %arrayidx13, align 4, !tbaa !7, !amdgpu.noclobber !11
  %add14 = fadd contract float %4, %5
  %arrayidx16 = getelementptr inbounds float, ptr addrspace(1) %c.coerce, i64 %idxprom
  store float %add14, ptr addrspace(1) %arrayidx16, align 4, !tbaa !7
  ret void
}
addPrivateSegmentBuffer: 4
addKernelArg0: 6
addKernelArg1: 8
addKernelArg2: 10
addKernargSegmentPtr: 12
kernarg 0
DAG.getCopyFromReg
kernarg 1
DAG.getCopyFromReg
kernarg 2
DAG.getCopyFromReg
# *** IR Dump After AMDGPU DAG->DAG Pattern Instruction Selection (amdgpu-isel) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %19:vgpr_32 = COPY %18:vgpr_32
  %20:vreg_64 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, killed %19:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64, implicit $exec
  %23:vreg_64_align2 = V_ADD_U64_PSEUDO %2:sgpr_64, %22:vreg_64_align2, implicit-def dead $vcc, implicit-def dead $exec, implicit $exec
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %25:vreg_64_align2 = V_ADD_U64_PSEUDO %3:sgpr_64, %22:vreg_64_align2, implicit-def dead $vcc, implicit-def dead $exec, implicit $exec
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %28:vreg_64_align2 = V_ADD_U64_PSEUDO %4:sgpr_64, %22:vreg_64_align2, implicit-def dead $vcc, implicit-def dead $exec, implicit $exec
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Fix SGPR copies (si-fix-sgpr-copies) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %19:vgpr_32 = COPY %18:vgpr_32
  %20:vreg_64 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, killed %19:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64, implicit $exec
  %23:vreg_64_align2 = V_ADD_U64_PSEUDO %2:sgpr_64, %22:vreg_64_align2, implicit-def dead $vcc, implicit-def dead $exec, implicit $exec
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %25:vreg_64_align2 = V_ADD_U64_PSEUDO %3:sgpr_64, %22:vreg_64_align2, implicit-def dead $vcc, implicit-def dead $exec, implicit $exec
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %28:vreg_64_align2 = V_ADD_U64_PSEUDO %4:sgpr_64, %22:vreg_64_align2, implicit-def dead $vcc, implicit-def dead $exec, implicit $exec
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Lower i1 Copies (si-i1-copies) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %19:vgpr_32 = COPY %18:vgpr_32
  %20:vreg_64 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, killed %19:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64, implicit $exec
  %23:vreg_64_align2 = V_ADD_U64_PSEUDO %2:sgpr_64, %22:vreg_64_align2, implicit-def dead $vcc, implicit-def dead $exec, implicit $exec
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %25:vreg_64_align2 = V_ADD_U64_PSEUDO %3:sgpr_64, %22:vreg_64_align2, implicit-def dead $vcc, implicit-def dead $exec, implicit $exec
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %28:vreg_64_align2 = V_ADD_U64_PSEUDO %4:sgpr_64, %22:vreg_64_align2, implicit-def dead $vcc, implicit-def dead $exec, implicit $exec
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Finalize ISel and expand pseudo-instructions (finalize-isel) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %19:vgpr_32 = COPY %18:vgpr_32
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, killed %19:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
  %33:sgpr_32 = COPY %2.sub0:sgpr_64
  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %35:sgpr_32 = COPY %2.sub1:sgpr_64
  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %37:vgpr_32 = COPY %35:sgpr_32
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %42:sgpr_32 = COPY %3.sub0:sgpr_64
  %43:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %44:sgpr_32 = COPY %3.sub1:sgpr_64
  %45:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %43:vgpr_32, 0, implicit $exec
  %46:vgpr_32 = COPY %44:sgpr_32
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %45:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %51:sgpr_32 = COPY %4.sub0:sgpr_64
  %52:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %53:sgpr_32 = COPY %4.sub1:sgpr_64
  %54:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %52:vgpr_32, 0, implicit $exec
  %55:vgpr_32 = COPY %53:sgpr_32
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %54:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Early Tail Duplication (early-tailduplication) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %19:vgpr_32 = COPY %18:vgpr_32
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, killed %19:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
  %33:sgpr_32 = COPY %2.sub0:sgpr_64
  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %35:sgpr_32 = COPY %2.sub1:sgpr_64
  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %37:vgpr_32 = COPY %35:sgpr_32
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %42:sgpr_32 = COPY %3.sub0:sgpr_64
  %43:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %44:sgpr_32 = COPY %3.sub1:sgpr_64
  %45:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %43:vgpr_32, 0, implicit $exec
  %46:vgpr_32 = COPY %44:sgpr_32
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %45:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %51:sgpr_32 = COPY %4.sub0:sgpr_64
  %52:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %53:sgpr_32 = COPY %4.sub1:sgpr_64
  %54:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %52:vgpr_32, 0, implicit $exec
  %55:vgpr_32 = COPY %53:sgpr_32
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %54:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Optimize machine instruction PHIs (opt-phis) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %19:vgpr_32 = COPY %18:vgpr_32
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, killed %19:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
  %33:sgpr_32 = COPY %2.sub0:sgpr_64
  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %35:sgpr_32 = COPY %2.sub1:sgpr_64
  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %37:vgpr_32 = COPY %35:sgpr_32
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %42:sgpr_32 = COPY %3.sub0:sgpr_64
  %43:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %44:sgpr_32 = COPY %3.sub1:sgpr_64
  %45:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %43:vgpr_32, 0, implicit $exec
  %46:vgpr_32 = COPY %44:sgpr_32
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %45:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %51:sgpr_32 = COPY %4.sub0:sgpr_64
  %52:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %53:sgpr_32 = COPY %4.sub1:sgpr_64
  %54:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %52:vgpr_32, 0, implicit $exec
  %55:vgpr_32 = COPY %53:sgpr_32
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %54:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Slot index numbering (slotindexes) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
32B	  %6:sgpr_32 = COPY $sgpr12
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
64B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
80B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
96B	  %0:vgpr_32(s32) = COPY $vgpr0
112B	  %9:sreg_32 = S_MOV_B32 8
128B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
144B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
160B	  %12:sreg_32 = S_MOV_B32 10
176B	  %14:vgpr_32 = COPY killed %12:sreg_32
192B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
208B	  %15:sreg_32 = S_MOV_B32 1023
224B	  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
240B	  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
256B	  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
272B	  %19:vgpr_32 = COPY %18:vgpr_32
288B	  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, killed %19:vgpr_32, %subreg.sub1
304B	  %21:sreg_32 = S_MOV_B32 2
320B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
336B	  %33:sgpr_32 = COPY %2.sub0:sgpr_64
352B	  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
368B	  %35:sgpr_32 = COPY %2.sub1:sgpr_64
384B	  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
400B	  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
416B	  %37:vgpr_32 = COPY %35:sgpr_32
432B	  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
448B	  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
464B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
480B	  %42:sgpr_32 = COPY %3.sub0:sgpr_64
496B	  %43:vgpr_32 = COPY %22.sub0:vreg_64_align2
512B	  %44:sgpr_32 = COPY %3.sub1:sgpr_64
528B	  %45:vgpr_32 = COPY %22.sub1:vreg_64_align2
544B	  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %43:vgpr_32, 0, implicit $exec
560B	  %46:vgpr_32 = COPY %44:sgpr_32
576B	  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %45:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
592B	  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
608B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
624B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
640B	  %51:sgpr_32 = COPY %4.sub0:sgpr_64
656B	  %52:vgpr_32 = COPY %22.sub0:vreg_64_align2
672B	  %53:sgpr_32 = COPY %4.sub1:sgpr_64
688B	  %54:vgpr_32 = COPY %22.sub1:vreg_64_align2
704B	  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %52:vgpr_32, 0, implicit $exec
720B	  %55:vgpr_32 = COPY %53:sgpr_32
736B	  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %54:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
752B	  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
768B	  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
784B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Merge disjoint stack slots (stack-coloring) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %19:vgpr_32 = COPY %18:vgpr_32
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, killed %19:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
  %33:sgpr_32 = COPY %2.sub0:sgpr_64
  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %35:sgpr_32 = COPY %2.sub1:sgpr_64
  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %37:vgpr_32 = COPY %35:sgpr_32
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %42:sgpr_32 = COPY %3.sub0:sgpr_64
  %43:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %44:sgpr_32 = COPY %3.sub1:sgpr_64
  %45:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %43:vgpr_32, 0, implicit $exec
  %46:vgpr_32 = COPY %44:sgpr_32
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %45:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %51:sgpr_32 = COPY %4.sub0:sgpr_64
  %52:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %53:sgpr_32 = COPY %4.sub1:sgpr_64
  %54:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %52:vgpr_32, 0, implicit $exec
  %55:vgpr_32 = COPY %53:sgpr_32
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %54:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Local Stack Slot Allocation (localstackalloc) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %19:vgpr_32 = COPY %18:vgpr_32
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, killed %19:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
  %33:sgpr_32 = COPY %2.sub0:sgpr_64
  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %35:sgpr_32 = COPY %2.sub1:sgpr_64
  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %37:vgpr_32 = COPY %35:sgpr_32
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %42:sgpr_32 = COPY %3.sub0:sgpr_64
  %43:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %44:sgpr_32 = COPY %3.sub1:sgpr_64
  %45:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %43:vgpr_32, 0, implicit $exec
  %46:vgpr_32 = COPY %44:sgpr_32
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %45:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %51:sgpr_32 = COPY %4.sub0:sgpr_64
  %52:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %53:sgpr_32 = COPY %4.sub1:sgpr_64
  %54:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %52:vgpr_32, 0, implicit $exec
  %55:vgpr_32 = COPY %53:sgpr_32
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %54:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %19:vgpr_32 = COPY %18:vgpr_32
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, killed %19:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
  %33:sgpr_32 = COPY %2.sub0:sgpr_64
  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %35:sgpr_32 = COPY %2.sub1:sgpr_64
  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %37:vgpr_32 = COPY %35:sgpr_32
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %42:sgpr_32 = COPY %3.sub0:sgpr_64
  %43:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %44:sgpr_32 = COPY %3.sub1:sgpr_64
  %45:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %43:vgpr_32, 0, implicit $exec
  %46:vgpr_32 = COPY %44:sgpr_32
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %45:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %51:sgpr_32 = COPY %4.sub0:sgpr_64
  %52:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %53:sgpr_32 = COPY %4.sub1:sgpr_64
  %54:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %52:vgpr_32, 0, implicit $exec
  %55:vgpr_32 = COPY %53:sgpr_32
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %54:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Early Machine Loop Invariant Code Motion (early-machinelicm) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %19:vgpr_32 = COPY %18:vgpr_32
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, killed %19:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
  %33:sgpr_32 = COPY %2.sub0:sgpr_64
  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %35:sgpr_32 = COPY %2.sub1:sgpr_64
  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %37:vgpr_32 = COPY %35:sgpr_32
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %42:sgpr_32 = COPY %3.sub0:sgpr_64
  %43:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %44:sgpr_32 = COPY %3.sub1:sgpr_64
  %45:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %43:vgpr_32, 0, implicit $exec
  %46:vgpr_32 = COPY %44:sgpr_32
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %45:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %51:sgpr_32 = COPY %4.sub0:sgpr_64
  %52:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %53:sgpr_32 = COPY %4.sub1:sgpr_64
  %54:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %52:vgpr_32, 0, implicit $exec
  %55:vgpr_32 = COPY %53:sgpr_32
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %54:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Machine Common Subexpression Elimination (machine-cse) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
  %33:sgpr_32 = COPY %2.sub0:sgpr_64
  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %35:sgpr_32 = COPY %2.sub1:sgpr_64
  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %37:vgpr_32 = COPY %35:sgpr_32
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %42:sgpr_32 = COPY %3.sub0:sgpr_64
  %43:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %44:sgpr_32 = COPY %3.sub1:sgpr_64
  %45:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %43:vgpr_32, 0, implicit $exec
  %46:vgpr_32 = COPY %44:sgpr_32
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %45:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %51:sgpr_32 = COPY %4.sub0:sgpr_64
  %52:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %53:sgpr_32 = COPY %4.sub1:sgpr_64
  %54:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %52:vgpr_32, 0, implicit $exec
  %55:vgpr_32 = COPY %53:sgpr_32
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %54:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Machine code sinking (machine-sink) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = COPY killed %12:sreg_32
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
  %33:sgpr_32 = COPY %2.sub0:sgpr_64
  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %35:sgpr_32 = COPY %2.sub1:sgpr_64
  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %37:vgpr_32 = COPY %35:sgpr_32
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %42:sgpr_32 = COPY %3.sub0:sgpr_64
  %43:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %44:sgpr_32 = COPY %3.sub1:sgpr_64
  %45:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %43:vgpr_32, 0, implicit $exec
  %46:vgpr_32 = COPY %44:sgpr_32
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %45:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %51:sgpr_32 = COPY %4.sub0:sgpr_64
  %52:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %53:sgpr_32 = COPY %4.sub1:sgpr_64
  %54:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %52:vgpr_32, 0, implicit $exec
  %55:vgpr_32 = COPY %53:sgpr_32
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %54:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Peephole Optimizations (peephole-opt) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %12:sreg_32 = S_MOV_B32 10
  %14:vgpr_32 = V_MOV_B32_e32 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
  %33:sgpr_32 = COPY %2.sub0:sgpr_64
  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %35:sgpr_32 = COPY %2.sub1:sgpr_64
  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %37:vgpr_32 = COPY %35:sgpr_32
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %42:sgpr_32 = COPY %3.sub0:sgpr_64
  %44:sgpr_32 = COPY %3.sub1:sgpr_64
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %46:vgpr_32 = COPY %44:sgpr_32
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %36:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %51:sgpr_32 = COPY %4.sub0:sgpr_64
  %53:sgpr_32 = COPY %4.sub1:sgpr_64
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %55:vgpr_32 = COPY %53:sgpr_32
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %36:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %9:sreg_32 = S_MOV_B32 8
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, killed %9:sreg_32, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %14:vgpr_32 = V_MOV_B32_e32 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, %14:vgpr_32, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %21:sreg_32 = S_MOV_B32 2
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 killed %21:sreg_32, killed %20:vreg_64_align2, implicit $exec
  %33:sgpr_32 = COPY %2.sub0:sgpr_64
  %34:vgpr_32 = COPY %22.sub0:vreg_64_align2
  %35:sgpr_32 = COPY %2.sub1:sgpr_64
  %36:vgpr_32 = COPY %22.sub1:vreg_64_align2
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %33:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %37:vgpr_32 = COPY %35:sgpr_32
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %36:vgpr_32, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %42:sgpr_32 = COPY %3.sub0:sgpr_64
  %44:sgpr_32 = COPY %3.sub1:sgpr_64
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %42:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %46:vgpr_32 = COPY %44:sgpr_32
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %36:vgpr_32, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %51:sgpr_32 = COPY %4.sub0:sgpr_64
  %53:sgpr_32 = COPY %4.sub1:sgpr_64
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %51:sgpr_32, %34:vgpr_32, 0, implicit $exec
  %55:vgpr_32 = COPY %53:sgpr_32
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %36:vgpr_32, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Fold Operands (si-fold-operands) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After GCN DPP Combine (gcn-dpp-combine) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Load Store Optimizer (si-load-store-opt) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Peephole SDWA (si-peephole-sdwa) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Early Machine Loop Invariant Code Motion (early-machinelicm) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Machine Common Subexpression Elimination (machine-cse) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Fold Operands (si-fold-operands) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %15:sreg_32 = S_MOV_B32 1023
  %16:vgpr_32 = V_AND_B32_e64 %0:vgpr_32(s32), killed %15:sreg_32, implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e64 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e64 0, killed %24:vgpr_32, 0, killed %26:vgpr_32, 0, 0, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Shrink Instructions (si-shrink-instructions) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Register Usage Information Propagation (reg-usage-propagation) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Detect Dead Lanes (detect-dead-lanes) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Process Implicit Definitions (processimpdefs) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Remove unreachable machine basic blocks (unreachable-mbb-elimination) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY $sgpr13
  %6:sgpr_32 = COPY $sgpr12
  %4:sgpr_64 = COPY $sgpr8_sgpr9
  %3:sgpr_64 = COPY $sgpr6_sgpr7
  %2:sgpr_64 = COPY $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY $vgpr0
  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE %17:vgpr_32, %subreg.sub0, %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE %29:vgpr_32, %subreg.sub0, %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE %38:vgpr_32, %subreg.sub0, %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE %47:vgpr_32, %subreg.sub0, %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Live Variable Analysis (livevars) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY killed $sgpr13
  %6:sgpr_32 = COPY killed $sgpr12
  %4:sgpr_64 = COPY killed $sgpr8_sgpr9
  %3:sgpr_64 = COPY killed $sgpr6_sgpr7
  %2:sgpr_64 = COPY killed $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY killed $vgpr0
  %10:sreg_32 = S_LSHL_B32 killed %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %16:vgpr_32 = V_AND_B32_e32 1023, killed %0:vgpr_32(s32), implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE killed %17:vgpr_32, %subreg.sub0, killed %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY killed %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 killed %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE killed %29:vgpr_32, %subreg.sub0, killed %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY killed %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 killed %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE killed %38:vgpr_32, %subreg.sub0, killed %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY killed %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 killed %55:vgpr_32, killed %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE killed %47:vgpr_32, %subreg.sub0, killed %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Optimize VGPR LiveRange (si-opt-vgpr-liverange) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: IsSSA, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY killed $sgpr13
  %6:sgpr_32 = COPY killed $sgpr12
  %4:sgpr_64 = COPY killed $sgpr8_sgpr9
  %3:sgpr_64 = COPY killed $sgpr6_sgpr7
  %2:sgpr_64 = COPY killed $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY killed $vgpr0
  %10:sreg_32 = S_LSHL_B32 killed %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %16:vgpr_32 = V_AND_B32_e32 1023, killed %0:vgpr_32(s32), implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE killed %17:vgpr_32, %subreg.sub0, killed %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY killed %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 killed %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE killed %29:vgpr_32, %subreg.sub0, killed %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY killed %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 killed %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE killed %38:vgpr_32, %subreg.sub0, killed %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY killed %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 killed %55:vgpr_32, killed %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE killed %47:vgpr_32, %subreg.sub0, killed %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Eliminate PHI nodes for register allocation (phi-node-elimination) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY killed $sgpr13
  %6:sgpr_32 = COPY killed $sgpr12
  %4:sgpr_64 = COPY killed $sgpr8_sgpr9
  %3:sgpr_64 = COPY killed $sgpr6_sgpr7
  %2:sgpr_64 = COPY killed $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY killed $vgpr0
  %10:sreg_32 = S_LSHL_B32 killed %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %16:vgpr_32 = V_AND_B32_e32 1023, killed %0:vgpr_32(s32), implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE killed %17:vgpr_32, %subreg.sub0, killed %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY killed %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 killed %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE killed %29:vgpr_32, %subreg.sub0, killed %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY killed %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 killed %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE killed %38:vgpr_32, %subreg.sub0, killed %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY killed %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 killed %55:vgpr_32, killed %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE killed %47:vgpr_32, %subreg.sub0, killed %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Lower control flow pseudo instructions (si-lower-control-flow) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY killed $sgpr13
  %6:sgpr_32 = COPY killed $sgpr12
  %4:sgpr_64 = COPY killed $sgpr8_sgpr9
  %3:sgpr_64 = COPY killed $sgpr6_sgpr7
  %2:sgpr_64 = COPY killed $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY killed $vgpr0
  %10:sreg_32 = S_LSHL_B32 killed %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %16:vgpr_32 = V_AND_B32_e32 1023, killed %0:vgpr_32(s32), implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
  %20:vreg_64_align2 = REG_SEQUENCE killed %17:vgpr_32, %subreg.sub0, killed %18:vgpr_32, %subreg.sub1
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY killed %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 killed %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  %23:vreg_64_align2 = REG_SEQUENCE killed %29:vgpr_32, %subreg.sub0, killed %30:vgpr_32, %subreg.sub1
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY killed %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 killed %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  %25:vreg_64_align2 = REG_SEQUENCE killed %38:vgpr_32, %subreg.sub0, killed %39:vgpr_32, %subreg.sub1
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY killed %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 killed %55:vgpr_32, killed %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  %28:vreg_64_align2 = REG_SEQUENCE killed %47:vgpr_32, %subreg.sub0, killed %48:vgpr_32, %subreg.sub1
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Two-Address instruction pass (twoaddressinstruction) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

bb.0.entry:
  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
  %7:sgpr_32 = COPY killed $sgpr13
  %6:sgpr_32 = COPY killed $sgpr12
  %4:sgpr_64 = COPY killed $sgpr8_sgpr9
  %3:sgpr_64 = COPY killed $sgpr6_sgpr7
  %2:sgpr_64 = COPY killed $sgpr4_sgpr5
  %0:vgpr_32(s32) = COPY killed $vgpr0
  %10:sreg_32 = S_LSHL_B32 killed %6:sgpr_32, 8, implicit-def dead $scc
  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
  %16:vgpr_32 = V_AND_B32_e32 1023, killed %0:vgpr_32(s32), implicit $exec
  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
  undef %20.sub0:vreg_64_align2 = COPY killed %17:vgpr_32
  %20.sub1:vreg_64_align2 = COPY killed %18:vgpr_32
  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %37:vgpr_32 = COPY killed %2.sub1:sgpr_64
  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 killed %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
  undef %23.sub0:vreg_64_align2 = COPY killed %29:vgpr_32
  %23.sub1:vreg_64_align2 = COPY killed %30:vgpr_32
  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %46:vgpr_32 = COPY killed %3.sub1:sgpr_64
  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 killed %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
  undef %25.sub0:vreg_64_align2 = COPY killed %38:vgpr_32
  %25.sub1:vreg_64_align2 = COPY killed %39:vgpr_32
  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
  %55:vgpr_32 = COPY killed %4.sub1:sgpr_64
  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 killed %55:vgpr_32, killed %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
  undef %28.sub0:vreg_64_align2 = COPY killed %47:vgpr_32
  %28.sub1:vreg_64_align2 = COPY killed %48:vgpr_32
  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Slot index numbering (slotindexes) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY killed $sgpr13
32B	  %6:sgpr_32 = COPY killed $sgpr12
48B	  %4:sgpr_64 = COPY killed $sgpr8_sgpr9
64B	  %3:sgpr_64 = COPY killed $sgpr6_sgpr7
80B	  %2:sgpr_64 = COPY killed $sgpr4_sgpr5
96B	  %0:vgpr_32(s32) = COPY killed $vgpr0
112B	  %10:sreg_32 = S_LSHL_B32 killed %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed %7:sgpr_32, killed %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, killed %0:vgpr_32(s32), implicit $exec
176B	  %17:vgpr_32 = nsw V_ADD3_U32_e64 killed %10:sreg_32, killed %16:vgpr_32, killed %13:vgpr_32, implicit $exec
192B	  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
208B	  undef %20.sub0:vreg_64_align2 = COPY killed %17:vgpr_32
224B	  %20.sub1:vreg_64_align2 = COPY killed %18:vgpr_32
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, killed %20:vreg_64_align2, implicit $exec
256B	  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
272B	  %37:vgpr_32 = COPY killed %2.sub1:sgpr_64
288B	  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 killed %37:vgpr_32, %22.sub1:vreg_64_align2, killed %31:sreg_64_xexec, 0, implicit $exec
304B	  undef %23.sub0:vreg_64_align2 = COPY killed %29:vgpr_32
320B	  %23.sub1:vreg_64_align2 = COPY killed %30:vgpr_32
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD killed %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
352B	  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
368B	  %46:vgpr_32 = COPY killed %3.sub1:sgpr_64
384B	  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 killed %46:vgpr_32, %22.sub1:vreg_64_align2, killed %40:sreg_64_xexec, 0, implicit $exec
400B	  undef %25.sub0:vreg_64_align2 = COPY killed %38:vgpr_32
416B	  %25.sub1:vreg_64_align2 = COPY killed %39:vgpr_32
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD killed %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
448B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 killed %24:vgpr_32, killed %26:vgpr_32, implicit $mode, implicit $exec
464B	  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
480B	  %55:vgpr_32 = COPY killed %4.sub1:sgpr_64
496B	  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 killed %55:vgpr_32, killed %22.sub1:vreg_64_align2, killed %49:sreg_64_xexec, 0, implicit $exec
512B	  undef %28.sub0:vreg_64_align2 = COPY killed %47:vgpr_32
528B	  %28.sub1:vreg_64_align2 = COPY killed %48:vgpr_32
544B	  GLOBAL_STORE_DWORD killed %28:vreg_64_align2, killed %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Live Interval Analysis (liveintervals) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
32B	  %6:sgpr_32 = COPY $sgpr12
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
64B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
80B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
96B	  %0:vgpr_32(s32) = COPY $vgpr0
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  %17:vgpr_32 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %18:vgpr_32 = V_ASHRREV_I32_e32 31, %17:vgpr_32, implicit $exec
208B	  undef %20.sub0:vreg_64_align2 = COPY %17:vgpr_32
224B	  %20.sub1:vreg_64_align2 = COPY %18:vgpr_32
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
256B	  %29:vgpr_32, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
288B	  %30:vgpr_32, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
304B	  undef %23.sub0:vreg_64_align2 = COPY %29:vgpr_32
320B	  %23.sub1:vreg_64_align2 = COPY %30:vgpr_32
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
352B	  %38:vgpr_32, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
384B	  %39:vgpr_32, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
400B	  undef %25.sub0:vreg_64_align2 = COPY %38:vgpr_32
416B	  %25.sub1:vreg_64_align2 = COPY %39:vgpr_32
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
448B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
464B	  %47:vgpr_32, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
496B	  %48:vgpr_32, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
512B	  undef %28.sub0:vreg_64_align2 = COPY %47:vgpr_32
528B	  %28.sub1:vreg_64_align2 = COPY %48:vgpr_32
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Simple Register Coalescing (simple-register-coalescing) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
32B	  %6:sgpr_32 = COPY $sgpr12
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
64B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
80B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
96B	  %0:vgpr_32(s32) = COPY $vgpr0
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
256B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
352B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
448B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
464B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Rename Disconnected Subregister Components (rename-independent-subregs) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
32B	  %6:sgpr_32 = COPY $sgpr12
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
64B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
80B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
96B	  %0:vgpr_32(s32) = COPY $vgpr0
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
256B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
352B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
448B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
464B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After AMDGPU Pre-RA optimizations (amdgpu-pre-ra-optimizations) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
32B	  %6:sgpr_32 = COPY $sgpr12
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
64B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
80B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
96B	  %0:vgpr_32(s32) = COPY $vgpr0
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
256B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
352B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
448B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
464B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Machine Instruction Scheduler (machine-scheduler) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Whole Quad Mode (si-wqm) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Virtual Register Map (virtregmap) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Live Register Matrix (liveregmatrix) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Pre-allocate WWM Registers (si-pre-allocate-wwm-regs) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI optimize exec mask operations pre-RA (si-optimize-exec-masking-pre-ra) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Form memory clauses (si-form-memory-clauses) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Debug Variable Analysis (livedebugvars) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Live Stack Slot Analysis (livestacks) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Virtual Register Map (virtregmap) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Live Register Matrix (liveregmatrix) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Greedy Register Allocator (greedy) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13
16B	  %7:sgpr_32 = COPY $sgpr13
24B	  %0:vgpr_32(s32) = COPY $vgpr0
32B	  %6:sgpr_32 = COPY $sgpr12
40B	  %3:sgpr_64 = COPY $sgpr6_sgpr7
44B	  %2:sgpr_64 = COPY $sgpr4_sgpr5
48B	  %4:sgpr_64 = COPY $sgpr8_sgpr9
112B	  %10:sreg_32 = S_LSHL_B32 %6:sgpr_32, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 %7:sgpr_32, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 %10:sreg_32, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY %2.sub1:sgpr_64
280B	  undef %23.sub0:vreg_64_align2, %31:sreg_64_xexec = V_ADD_CO_U32_e64 %2.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead %32:sreg_64_xexec = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, %31:sreg_64_xexec, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY %3.sub1:sgpr_64
376B	  undef %25.sub0:vreg_64_align2, %40:sreg_64_xexec = V_ADD_CO_U32_e64 %3.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead %41:sreg_64_xexec = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, %40:sreg_64_xexec, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY %4.sub1:sgpr_64
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, %49:sreg_64_xexec = V_ADD_CO_U32_e64 %4.sub0:sgpr_64, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead %50:sreg_64_xexec = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, %49:sreg_64_xexec, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Virtual Register Rewriter (virtregrewriter) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
24B	  %0:vgpr_32(s32) = COPY $vgpr0
112B	  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 killed $sgpr0, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY renamable $sgpr5
280B	  undef %23.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY renamable $sgpr7
376B	  undef %25.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY renamable $sgpr9
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI lower SGPR spill instructions (si-lower-sgpr-spills) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
24B	  %0:vgpr_32(s32) = COPY $vgpr0
112B	  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 killed $sgpr0, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY renamable $sgpr5
280B	  undef %23.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY renamable $sgpr7
376B	  undef %25.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY renamable $sgpr9
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Virtual Register Map (virtregmap) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
24B	  %0:vgpr_32(s32) = COPY $vgpr0
112B	  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 killed $sgpr0, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY renamable $sgpr5
280B	  undef %23.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY renamable $sgpr7
376B	  undef %25.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY renamable $sgpr9
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Live Register Matrix (liveregmatrix) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
24B	  %0:vgpr_32(s32) = COPY $vgpr0
112B	  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 killed $sgpr0, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY renamable $sgpr5
280B	  undef %23.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY renamable $sgpr7
376B	  undef %25.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY renamable $sgpr9
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Greedy Register Allocator (greedy) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
24B	  %0:vgpr_32(s32) = COPY $vgpr0
112B	  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 killed $sgpr0, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY renamable $sgpr5
280B	  undef %23.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY renamable $sgpr7
376B	  undef %25.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY renamable $sgpr9
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After GCN NSA Reassign (amdgpu-nsa-reassign) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0 in %0, $sgpr4_sgpr5 in %2, $sgpr6_sgpr7 in %3, $sgpr8_sgpr9 in %4, $sgpr12 in %6, $sgpr13 in %7

0B	bb.0.entry:
	  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
24B	  %0:vgpr_32(s32) = COPY $vgpr0
112B	  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
128B	  %11:vgpr_32 = V_BFE_U32_e64 %0:vgpr_32(s32), 10, 10, implicit $exec
144B	  %13:vgpr_32 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, %11:vgpr_32, 10, implicit $exec
160B	  %16:vgpr_32 = V_AND_B32_e32 1023, %0:vgpr_32(s32), implicit $exec
176B	  undef %20.sub0:vreg_64_align2 = nsw V_ADD3_U32_e64 killed $sgpr0, %16:vgpr_32, %13:vgpr_32, implicit $exec
192B	  %20.sub1:vreg_64_align2 = V_ASHRREV_I32_e32 31, %20.sub0:vreg_64_align2, implicit $exec
240B	  %22:vreg_64_align2 = V_LSHLREV_B64_e64 2, %20:vreg_64_align2, implicit $exec
272B	  %37:vgpr_32 = COPY renamable $sgpr5
280B	  undef %23.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, %22.sub0:vreg_64_align2, 0, implicit $exec
288B	  %23.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %37:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
336B	  %24:vgpr_32 = GLOBAL_LOAD_DWORD %23:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  %46:vgpr_32 = COPY renamable $sgpr7
376B	  undef %25.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, %22.sub0:vreg_64_align2, 0, implicit $exec
384B	  %25.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %46:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
432B	  %26:vgpr_32 = GLOBAL_LOAD_DWORD %25:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  %55:vgpr_32 = COPY renamable $sgpr9
484B	  %27:vgpr_32 = contract nofpexcept V_ADD_F32_e32 %24:vgpr_32, %26:vgpr_32, implicit $mode, implicit $exec
488B	  undef %28.sub0:vreg_64_align2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, %22.sub0:vreg_64_align2, 0, implicit $exec
496B	  %28.sub1:vreg_64_align2, dead renamable $vcc = V_ADDC_U32_e64 %55:vgpr_32, %22.sub1:vreg_64_align2, killed $vcc, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD %28:vreg_64_align2, %27:vgpr_32, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Virtual Register Rewriter (virtregrewriter) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

0B	bb.0.entry:
	  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
112B	  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
128B	  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
144B	  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
160B	  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
176B	  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
192B	  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
240B	  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
272B	  renamable $vgpr3 = COPY renamable $sgpr5
280B	  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
288B	  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
336B	  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  renamable $vgpr3 = COPY renamable $sgpr7
376B	  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
384B	  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
432B	  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  renamable $vgpr3 = COPY renamable $sgpr9
484B	  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
488B	  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
496B	  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Stack Slot Coloring (stack-slot-coloring) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

0B	bb.0.entry:
	  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
112B	  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
128B	  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
144B	  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
160B	  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
176B	  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
192B	  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
240B	  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
272B	  renamable $vgpr3 = COPY renamable $sgpr5
280B	  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
288B	  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
336B	  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
368B	  renamable $vgpr3 = COPY renamable $sgpr7
376B	  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
384B	  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
432B	  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
480B	  renamable $vgpr3 = COPY renamable $sgpr9
484B	  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
488B	  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
496B	  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
544B	  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
560B	  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Machine Copy Propagation Pass (machine-cp) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Machine Loop Invariant Code Motion (machinelicm) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Fix VGPR copies (si-fix-vgpr-copies) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI optimize exec mask operations (si-optimize-exec-masking) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Remove Redundant DEBUG_VALUE analysis (removeredundantdebugvalues) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Fixup Statepoint Caller Saved (fixup-statepoint-caller-saved) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After PostRA Machine Sink (postra-machine-sink) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Shrink Wrapping analysis (shrink-wrap) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Prologue/Epilogue Insertion & Frame Finalization (prologepilog) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Control Flow Optimizer (branch-folder) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Tail Duplication (tailduplication) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Machine Copy Propagation Pass (machine-cp) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  renamable $vgpr3 = COPY renamable $sgpr5, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr7, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  renamable $vgpr3 = COPY renamable $sgpr9, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Post-RA pseudo instruction expansion pass (postrapseudos) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr4, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr6, $vgpr0, 0, implicit $exec
  renamable $vgpr3, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, $vgpr1, killed $vcc, 0, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0, renamable $vcc = V_ADD_CO_U32_e64 killed $sgpr8, $vgpr0, 0, implicit $exec
  renamable $vgpr1, dead renamable $vcc = V_ADDC_U32_e64 killed $vgpr3, killed $vgpr1, killed $vcc, 0, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Shrink Instructions (si-shrink-instructions) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI post-RA bundler (si-post-ra-bundler) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After PostRA Machine Instruction Scheduler (postmisched) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Branch Probability Basic Block Placement (block-placement) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Insert fentry calls (fentry-insert) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Insert XRay ops (xray-instrumentation) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After GCN Create VOPD Instructions (gcn-create-vopd) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Memory Legalizer (si-memory-legalizer) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI insert wait instructions (si-insert-waitcnts) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  S_WAITCNT 3952
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Insert required mode register values (si-mode-register) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  S_WAITCNT 3952
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Insert Hard Clauses (si-insert-hard-clauses) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  S_WAITCNT 3952
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI Final Branch Preparation (si-late-branch-lowering) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  S_WAITCNT 3952
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After SI peephole optimizations (si-pre-emit-peephole) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  S_WAITCNT 3952
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Post RA hazard recognizer (post-RA-hazard-rec) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  S_WAITCNT 3952
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Release VGPRs (release-vgprs) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  S_WAITCNT 3952
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After AMDGPU Insert Delay ALU (amdgpu-insert-delay-alu) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  S_WAITCNT 3952
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Branch relaxation pass (branch-relaxation) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  S_WAITCNT 3952
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Register Usage Information Collector Pass (RegUsageInfoCollector) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  S_WAITCNT 3952
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

# *** IR Dump After Live DEBUG_VALUE analysis (livedebugvalues) ***:
# Machine code for function _Z15vectoradd_floatPKfS0_Pf: NoPHIs, TracksLiveness, NoVRegs, TiedOpsRewritten, TracksDebugUserValues
Function Live Ins: $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9, $sgpr12, $sgpr13

bb.0.entry:
  liveins: $sgpr12, $sgpr13, $vgpr0, $sgpr4_sgpr5, $sgpr6_sgpr7, $sgpr8_sgpr9
  renamable $vgpr1 = V_BFE_U32_e64 $vgpr0, 10, 10, implicit $exec
  renamable $sgpr0 = S_LSHL_B32 killed renamable $sgpr12, 8, implicit-def dead $scc
  renamable $vgpr1 = nsw V_ADD_LSHL_U32_e64 killed $sgpr13, killed $vgpr1, 10, implicit $exec
  renamable $vgpr0 = V_AND_B32_e32 1023, killed $vgpr0, implicit $exec
  renamable $vgpr0 = nsw V_ADD3_U32_e64 killed $sgpr0, killed $vgpr0, killed $vgpr1, implicit $exec
  renamable $vgpr1 = V_ASHRREV_I32_e32 31, $vgpr0, implicit $exec
  renamable $vgpr0_vgpr1 = V_LSHLREV_B64_e64 2, killed $vgpr0_vgpr1, implicit $exec
  $vgpr3 = V_MOV_B32_e32 killed $sgpr5, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr4, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr4 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr7, implicit $exec, implicit $exec
  renamable $vgpr2 = V_ADD_CO_U32_e32 killed $sgpr6, $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr3 = V_ADDC_U32_e32 killed $vgpr3, $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  renamable $vgpr2 = GLOBAL_LOAD_DWORD killed renamable $vgpr2_vgpr3, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s32) from %ir.arrayidx13, !tbaa !7, addrspace 1)
  $vgpr3 = V_MOV_B32_e32 killed $sgpr9, implicit $exec, implicit $exec
  renamable $vgpr0 = V_ADD_CO_U32_e32 killed $sgpr8, killed $vgpr0, implicit-def $vcc, implicit $exec
  renamable $vgpr1 = V_ADDC_U32_e32 killed $vgpr3, killed $vgpr1, implicit-def dead $vcc, implicit killed $vcc, implicit $exec
  S_WAITCNT 3952
  renamable $vgpr2 = contract nofpexcept V_ADD_F32_e32 killed $vgpr4, killed $vgpr2, implicit $mode, implicit $exec
  GLOBAL_STORE_DWORD killed renamable $vgpr0_vgpr1, killed renamable $vgpr2, 0, 0, implicit $exec :: (store (s32) into %ir.arrayidx16, !tbaa !7, addrspace 1)
  S_ENDPGM 0

# End machine code for function _Z15vectoradd_floatPKfS0_Pf.

*** IR Dump After AMDGPU Annotate Kernel Features (amdgpu-annotate-kernel-features) ***
Printing <null> Function
*** IR Dump After DummyCGSCCPass (DummyCGSCCPass) ***
Printing <null> Function
